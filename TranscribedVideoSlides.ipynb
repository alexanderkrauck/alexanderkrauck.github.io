{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexanderkrauck/alexanderkrauck.github.io/blob/main/TranscribedVideoSlides.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBq5aSv-wome",
        "outputId": "3d505115-573c-4ffa-b917-eb0529393294"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Collecting SpeechRecognition\n",
            "  Downloading SpeechRecognition-3.11.0-py2.py3-none-any.whl.metadata (28 kB)\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.54.4)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Collecting fpdf\n",
            "  Downloading fpdf-1.7.2.tar.gz (39 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.36.0)\n",
            "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.5.1)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.66.6)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.32.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (4.12.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.7.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (5.3.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy) (11.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio_ffmpeg>=0.2.0->moviepy) (75.1.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.2.3)\n",
            "Downloading SpeechRecognition-3.11.0-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: fpdf\n",
            "  Building wheel for fpdf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fpdf: filename=fpdf-1.7.2-py2.py3-none-any.whl size=40704 sha256=341db92ec36b8a8ee4eb6d3d6c653a26f4c3f91d22aa8a573ed232e096565b88\n",
            "  Stored in directory: /root/.cache/pip/wheels/f9/95/ba/f418094659025eb9611f17cbcaf2334236bf39a0c3453ea455\n",
            "Successfully built fpdf\n",
            "Installing collected packages: pydub, fpdf, python-docx, SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.11.0 fpdf-1.7.2 pydub-0.25.1 python-docx-1.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install moviepy SpeechRecognition pydub opencv-python-headless numpy openai opencv-contrib-python fpdf python-docx moviepy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nmDnbZGT--Ml"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "openai_api_key = userdata.get('OPENAI_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jDE19tkdZtPk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95ec1d38-7b21-4a7c-9a13-ac77d69dae40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/moviepy/video/io/sliders.py:61: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if event.key is 'enter':\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from moviepy.editor import VideoFileClip\n",
        "import openai\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, Markdown\n",
        "from openai import OpenAI\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "import base64\n",
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "# Initialize OpenAI client\n",
        "client = OpenAI(api_key=openai_api_key)\n",
        "openai.api_key = openai_api_key\n",
        "\n",
        "def detect_slide_changes(video_path, sample_rate=10, ssim_threshold=0.9):\n",
        "    print(\"Starting slide change detection...\")\n",
        "    video = cv2.VideoCapture(video_path)\n",
        "    fps = video.get(cv2.CAP_PROP_FPS)\n",
        "    frame_interval = int(fps * sample_rate)\n",
        "    total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    duration = total_frames / fps\n",
        "\n",
        "    print(f\"Video FPS: {fps}\")\n",
        "    print(f\"Total frames: {total_frames}\")\n",
        "    print(f\"Video duration: {duration:.2f} seconds\")\n",
        "    print(f\"Frame interval: {frame_interval} frames (every {sample_rate} seconds)\")\n",
        "\n",
        "    slide_changes = []\n",
        "    frames = []\n",
        "    timestamps = []\n",
        "\n",
        "    success, prev_frame = video.read()\n",
        "    if not success:\n",
        "        print(\"Failed to read the first frame of the video.\")\n",
        "        return [], [], []\n",
        "\n",
        "    prev_frame_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
        "    frame_count = frame_interval\n",
        "    current_time = 0\n",
        "\n",
        "    slide_changes.append(0)  # Start with the first frame\n",
        "    frames.append(prev_frame)\n",
        "    timestamps.append(current_time)\n",
        "\n",
        "    print(\"Analyzing frames for slide changes...\")\n",
        "    with tqdm(total=total_frames, desc=\"Frames Processed\", unit=\"frame\") as pbar:\n",
        "        while frame_count < total_frames:\n",
        "            video.set(cv2.CAP_PROP_POS_FRAMES, frame_count)\n",
        "            success, frame = video.read()\n",
        "            if not success:\n",
        "                print(f\"Failed to read frame at position {frame_count}.\")\n",
        "                break\n",
        "\n",
        "            current_time = frame_count / fps\n",
        "\n",
        "            frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "            score, _ = ssim(prev_frame_gray, frame_gray, full=True)\n",
        "\n",
        "            if score < ssim_threshold:\n",
        "                # Significant change detected\n",
        "                print(f\"Slide change detected at {current_time:.2f} seconds (frame {frame_count}). SSIM: {score:.4f}\")\n",
        "                slide_changes.append(current_time)\n",
        "                frames.append(frame)\n",
        "                timestamps.append(current_time)\n",
        "                prev_frame_gray = frame_gray\n",
        "            else:\n",
        "                # No significant change\n",
        "                pass  # You can add additional logging here if desired\n",
        "\n",
        "            prev_frame_gray = frame_gray\n",
        "            increment = min(frame_interval, total_frames - frame_count)\n",
        "            frame_count += frame_interval\n",
        "            pbar.update(increment)\n",
        "\n",
        "    video.release()\n",
        "\n",
        "    # Append the last timestamp if not included\n",
        "    if slide_changes[-1] != duration:\n",
        "        slide_changes.append(duration)\n",
        "        print(f\"Adding final slide change at end of video ({duration:.2f} seconds).\")\n",
        "\n",
        "    print(f\"Total slide changes detected: {len(slide_changes) - 1}\")\n",
        "    return slide_changes, frames, timestamps\n",
        "\n",
        "\n",
        "# MoviePy replacement for extracting audio segment\n",
        "def extract_audio_with_moviepy(video_path, start_time, end_time, output_audio_path):\n",
        "    try:\n",
        "        video = VideoFileClip(video_path).subclip(start_time, end_time)\n",
        "        video.audio.write_audiofile(output_audio_path, codec=\"pcm_s16le\", fps=16000, nbytes=2, buffersize=2000)\n",
        "        print(f\"Audio extracted to {output_audio_path}.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting audio with moviepy: {e}\")\n",
        "\n",
        "def transcribe_audio(start_time, end_time, segment_index, video_path):\n",
        "    print(f\"Transcribing audio for segment {segment_index} from {start_time:.2f}s to {end_time:.2f}s...\")\n",
        "    temp_audio_file = f\"temp_audio_{segment_index}.wav\"\n",
        "    # Use ffmpeg to extract the audio segment\n",
        "    #ffmpeg_command = f\"ffmpeg -y -i \\\"{video_path}\\\" -ss {start_time} -to {end_time} -vn -acodec pcm_s16le -ar 16000 -ac 1 \\\"{temp_audio_file}\\\" -loglevel quiet\"\n",
        "    #os.system(ffmpeg_command)\n",
        "    extract_audio_with_moviepy(video_path, start_time, end_time, temp_audio_file)\n",
        "\n",
        "    try:\n",
        "        with open(temp_audio_file, \"rb\") as audio_file:\n",
        "            transcript = client.audio.transcriptions.create(\n",
        "                model=\"whisper-1\",\n",
        "                file=audio_file\n",
        "            )\n",
        "        print(f\"Transcription for segment {segment_index} completed.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error during transcription of segment {segment_index}: {e}\")\n",
        "        transcript = None\n",
        "\n",
        "    os.remove(temp_audio_file)\n",
        "    return transcript.text if transcript else \"\"\n",
        "\n",
        "# Function to encode the frame image to base64\n",
        "def encode_image_from_frame(frame):\n",
        "    print(\"Encoding slide image to base64...\")\n",
        "    # Convert the frame to JPEG format\n",
        "    _, buffer = cv2.imencode('.jpg', frame)\n",
        "    base64_image = base64.b64encode(buffer).decode('utf-8')\n",
        "    print(\"Image encoding completed.\")\n",
        "    return base64_image\n",
        "\n",
        "def summarize_slide(transcription, base64_image, segment_index):\n",
        "    print(f\"Generating summary for segment {segment_index}...\")\n",
        "    # Prepare the message content\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\n",
        "                    \"type\": \"text\",\n",
        "                    \"text\": \"Please provide a comprehensive summary that combines the information from the slide image and the transcription.\"\n",
        "                },\n",
        "                {\n",
        "                    \"type\": \"image_url\",\n",
        "                    \"image_url\": {\n",
        "                        \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
        "                    },\n",
        "                },\n",
        "                {\n",
        "                    \"type\": \"text\",\n",
        "                    \"text\": f\"Transcription:\\n{transcription}\"\n",
        "                },\n",
        "            ],\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=messages\n",
        "        )\n",
        "        summary = response.choices[0].message.content\n",
        "        print(f\"Summary generation for segment {segment_index} completed.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error during summary generation for segment {segment_index}: {e}\")\n",
        "        summary = \"\"\n",
        "    return summary\n",
        "\n",
        "def main(video_path, sample_rate=10, ssim_threshold=0.9):\n",
        "    print(\"Starting main processing...\")\n",
        "    print(\"Step 1: Detecting slide changes...\")\n",
        "    slide_changes, frames, timestamps = detect_slide_changes(video_path, sample_rate, ssim_threshold)\n",
        "\n",
        "    if not slide_changes:\n",
        "        print(\"No slide changes detected. Exiting.\")\n",
        "        return []\n",
        "\n",
        "    print(\"\\nStep 2: Processing slides and audio...\")\n",
        "    results = []\n",
        "    duration = VideoFileClip(video_path).duration\n",
        "\n",
        "    for i in tqdm(range(len(slide_changes) - 1), desc=\"Segments Processed\", unit=\"segment\"):\n",
        "        start_time = slide_changes[i]\n",
        "        end_time = slide_changes[i+1]\n",
        "        frame = frames[i]\n",
        "        timestamp = start_time\n",
        "\n",
        "        print(f\"\\nProcessing segment {i}: {start_time:.2f}s to {end_time:.2f}s\")\n",
        "\n",
        "        # Transcribe audio\n",
        "        transcription = transcribe_audio(start_time, end_time, i, video_path)\n",
        "\n",
        "        # Encode the slide image to base64\n",
        "        base64_image = encode_image_from_frame(frame)\n",
        "\n",
        "        # Summarize transcription and slide image\n",
        "        summary = summarize_slide(transcription, base64_image, i)\n",
        "\n",
        "        # Collect results\n",
        "        results.append({\n",
        "            'timestamp': timestamp,\n",
        "            'frame': frame,\n",
        "            'transcription': transcription,\n",
        "            'summary': summary\n",
        "        })\n",
        "\n",
        "    print(\"\\nProcessing completed.\")\n",
        "    return results\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from docx import Document\n",
        "from docx.shared import Inches\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "import tempfile\n",
        "\n",
        "def get_filename_without_extension(path):\n",
        "    # Get the base name of the path (filename with extension)\n",
        "    filename_with_ext = os.path.basename(path)\n",
        "    # Split the extension from the filename\n",
        "    filename_without_ext, _ = os.path.splitext(filename_with_ext)\n",
        "    return filename_without_ext\n",
        "\n",
        "def export_results(results, output_filename=\"my_analysis.docx\"):\n",
        "    \"\"\"\n",
        "    Export results to DOCX format\n",
        "\n",
        "    Args:\n",
        "        results: List of dictionaries containing timestamp, frame, transcription, and summary\n",
        "        output_filename: Name of output file (should end with .docx)\n",
        "    \"\"\"\n",
        "    # Create temporary directory for images\n",
        "    with tempfile.TemporaryDirectory() as temp_dir:\n",
        "        doc = Document()\n",
        "\n",
        "        for idx, result in enumerate(results):\n",
        "            # Save the frame as an image\n",
        "            frame = result['frame']\n",
        "            img_path = os.path.join(temp_dir, f'frame_{idx}.png')\n",
        "\n",
        "            # Convert BGR to RGB and save\n",
        "            plt.figure(figsize=(10, 6))\n",
        "            plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "            plt.axis('off')\n",
        "            plt.savefig(img_path, bbox_inches='tight', pad_inches=0)\n",
        "            plt.close()\n",
        "\n",
        "            # Add timestamp\n",
        "            doc.add_heading(f\"Timestamp: {result['timestamp']:.2f} seconds\", level=1)\n",
        "\n",
        "            # Add image\n",
        "            doc.add_picture(img_path, width=Inches(6))\n",
        "\n",
        "            # Add summary\n",
        "            doc.add_heading(\"Summary:\", level=2)\n",
        "            doc.add_paragraph(result['summary'])\n",
        "\n",
        "            # Add transcription if available\n",
        "            #if result.get('transcription'):\n",
        "            #    doc.add_heading(\"Transcription:\", level=2)\n",
        "            #    doc.add_paragraph(result['transcription'])\n",
        "\n",
        "            # Add separator except for the last item\n",
        "            if idx < len(results) - 1:\n",
        "                doc.add_paragraph(\"---\")\n",
        "                doc.add_page_break()\n",
        "\n",
        "        # Save the document\n",
        "        doc.save(output_filename)\n",
        "\n",
        "        print(f\"Document saved as {output_filename}\")\n",
        "\n",
        "# Example usage:\n",
        "# export_results(results, \"my_analysis.docx\")"
      ],
      "metadata": {
        "id": "dgP9jo5iezHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "os.makedirs(\"outputs\", exist_ok=True)"
      ],
      "metadata": {
        "id": "BYChAQPMmM0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all MP4 files in the directory and its subdirectories\n",
        "directory = \"/content\"\n",
        "mp4_files = list(Path(directory).rglob(\"*.mp4\"))\n",
        "\n",
        "if not mp4_files:\n",
        "    print(f\"No MP4 files found in {directory} or its subdirectories\")\n",
        "else:\n",
        "    print(f\"Found {len(mp4_files)} MP4 files to process\")\n",
        "\n",
        "    # Process each video\n",
        "    for video_path in mp4_files:\n",
        "        try:\n",
        "            print(f\"\\nProcessing: {str(video_path)}\")\n",
        "\n",
        "            # Generate output filename\n",
        "            output_file = \"/content/outputs/\"+ str(video_path).split(\"/\")[-1].split(\".\")[0] + \".docx\"\n",
        "\n",
        "            # Process the video\n",
        "            results = main(str(video_path), sample_rate=10, ssim_threshold=0.9)\n",
        "\n",
        "            # Export results\n",
        "            export_results(results, output_file)\n",
        "\n",
        "            print(f\"Successfully processed: {str(video_path)}\")\n",
        "            print(f\"Output saved as: {output_file}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {str(video_path)}: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "    print(\"\\nProcessing complete!\")"
      ],
      "metadata": {
        "id": "jX-7ruLRmG9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# Replace these paths with your folder and output file paths\n",
        "folder_to_compress = \"/content/outputs\"\n",
        "output_zip = \"/content/words\"\n",
        "\n",
        "# Ensure the parent directory of the output exists\n",
        "os.makedirs(os.path.dirname(output_zip), exist_ok=True)\n",
        "\n",
        "# Compress the folder\n",
        "shutil.make_archive(output_zip, 'zip', folder_to_compress)\n",
        "\n",
        "print(f\"Folder '{folder_to_compress}' has been compressed to '{output_zip}.zip'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWLalPxCzI5a",
        "outputId": "31641f99-3d10-4d08-efe0-eae3f6221577"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder '/content/outputs' has been compressed to '/content/words.zip'\n",
            "Folder '/content/outputs' has been compressed to '/content/words.zip'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "def move_file(source_path, destination_path):\n",
        "    \"\"\"\n",
        "    Move a file from source to destination path.\n",
        "    Creates destination directory if it doesn't exist.\n",
        "    \"\"\"\n",
        "    # Create destination directory if needed\n",
        "    os.makedirs(os.path.dirname(destination_path), exist_ok=True)\n",
        "\n",
        "    # Move the file\n",
        "    shutil.move(source_path, destination_path)"
      ],
      "metadata": {
        "id": "_awM-p0nNE1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "move_file('/content/words.zip', '/content/drive/MyDrive/file.zip')"
      ],
      "metadata": {
        "id": "fjV-jLxw4arh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ov5bv99d4gb5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1FftP8rx2BrcNSfUGEa_W70_w49i-NNbG",
      "authorship_tag": "ABX9TyMFQpl5O59PW5SG7G/+7Mgd",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}